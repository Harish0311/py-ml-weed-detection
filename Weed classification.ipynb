{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"KuLTWrCNdofH"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n","from keras.utils import np_utils\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import StandardScaler,LabelEncoder\n","from sklearn.metrics import classification_report,confusion_matrix\n","import os\n","import random\n","import shutil\n","from shutil import copyfile\n","from keras.preprocessing.image import ImageDataGenerator\n","import cv2"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"a7XHrz38efh9"},"outputs":[],"source":["values = ['crop','weed']"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"3KBJZ1VSefel"},"outputs":[],"source":["dest_dir='./dataset/'\n","train_dir=dest_dir+'training/'\n","val_dir=dest_dir+'validation/'"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Configured TensorFlow to use GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"]}],"source":["\n","# Specify the GPU device to use\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","  try:\n","    # Restrict TensorFlow to use only the first GPU\n","    tf.config.set_visible_devices(gpus[0], 'GPU')\n","    # Allow memory growth to prevent out-of-memory errors\n","    tf.config.experimental.set_memory_growth(gpus[0], True)\n","    print('Configured TensorFlow to use GPU:', gpus[0])\n","  except RuntimeError as e:\n","    print(e)\n","else:\n","  print('No GPU detected, using CPU instead.')\n","\n","# Your TensorFlow code here...\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZWmWYvgVfRPF"},"source":["Image Data Generator"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"R7QhQpe3efYH"},"outputs":[],"source":["def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n","  train_datagen = ImageDataGenerator(rescale=1/255)\n","  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n","                                                      batch_size=512,\n","                                                      class_mode='categorical',\n","                                                      target_size=(200,200))\n"," \n","  validation_datagen = ImageDataGenerator(rescale=1/255,\n","                                    #  rotation_range=40,\n","                                    #  width_shift_range=0.2,\n","                                    #  height_shift_range=0.2,\n","                                    #  shear_range=0.2,\n","                                    #  zoom_range=0.2,\n","                                    #  horizontal_flip=True,\n","                                    #  fill_mode='nearest'\n","                                     )\n","  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n","                                                                batch_size=512,\n","                                                                class_mode='categorical',\n","                                                                target_size=(200,200))\n","  return train_generator, validation_generator"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"AHk4RaQPefVv"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1040 images belonging to 2 classes.\n","Found 260 images belonging to 2 classes.\n"]}],"source":["train_generator, validation_generator = train_val_generators(train_dir,val_dir)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PFXZp8fVffS7"},"source":["Model building"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"f3mjlHi9efTc"},"outputs":[],"source":["#parameters\n","img_height=512\n","img_width=512\n","num_classes=2\n","do=0.5\n","reg=tf.keras.regularizers.l2(l2=0.0015)\n","batch_size=512\n","epochs=30"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"CP4aS1uDefOq"},"outputs":[],"source":["def create_model():\n","  model = Sequential([\n","    Conv2D(32, 3 , activation='relu',input_shape=(img_height, img_width, 3)),\n","    Conv2D(32, 3 ,  activation='relu',padding='same'),\n","    MaxPooling2D(pool_size=4),\n","    #Dropout(do),\n","\n","    Conv2D(64, 3 ,  activation='relu',padding='same'),\n","    Conv2D(64, 3 ,  activation='relu'),\n","    MaxPooling2D(pool_size=4),\n","    #Dropout(do),\n","\n","    Conv2D(64, 3 ,  activation='relu',padding='same'),\n","    Conv2D(64, 3 ,  activation='relu'),\n","    MaxPooling2D(pool_size=4),\n","    #Dropout(do),\n","\n","    Flatten(),\n","    Dense(512, activation='relu'),\n","    # Dropout(2*do),\n","    Dense(num_classes, activation='softmax')\n","    ])\n","  model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","  return model"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"vNhqMKHmefC1"},"outputs":[],"source":["model=create_model()"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"61r8Yjsef-be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_18 (Conv2D)          (None, 510, 510, 32)      896       \n","                                                                 \n"," conv2d_19 (Conv2D)          (None, 510, 510, 32)      9248      \n","                                                                 \n"," max_pooling2d_9 (MaxPooling  (None, 127, 127, 32)     0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_20 (Conv2D)          (None, 127, 127, 64)      18496     \n","                                                                 \n"," conv2d_21 (Conv2D)          (None, 125, 125, 64)      36928     \n","                                                                 \n"," max_pooling2d_10 (MaxPoolin  (None, 31, 31, 64)       0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_22 (Conv2D)          (None, 31, 31, 64)        36928     \n","                                                                 \n"," conv2d_23 (Conv2D)          (None, 29, 29, 64)        36928     \n","                                                                 \n"," max_pooling2d_11 (MaxPoolin  (None, 7, 7, 64)         0         \n"," g2D)                                                            \n","                                                                 \n"," flatten_3 (Flatten)         (None, 3136)              0         \n","                                                                 \n"," dense_6 (Dense)             (None, 512)               1606144   \n","                                                                 \n"," dropout_2 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_7 (Dense)             (None, 2)                 1026      \n","                                                                 \n","=================================================================\n","Total params: 1,746,594\n","Trainable params: 1,746,594\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"CVC-A9JMguly"},"outputs":[],"source":["callbacks=keras.callbacks.ModelCheckpoint('./../checkpoints/checkpoint-{epoch}.h5', save_best_only=True)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"9SJs9f4OgEex"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n"]},{"ename":"ValueError","evalue":"in user code:\n\n    File \"c:\\Users\\haris\\miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\haris\\miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\haris\\miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\haris\\miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\haris\\miniconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"dropout_2\" \"                 f\"(type Dropout).\n    \n    `rate` must be a scalar tensor or a float in the range [0, 1). Received: rate=1.0\n    \n    Call arguments received by layer \"dropout_2\" \"                 f\"(type Dropout):\n      • inputs=tf.Tensor(shape=(None, 512), dtype=float32)\n      • training=True\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      2\u001b[0m     train_generator,\n\u001b[0;32m      3\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m      4\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m      5\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m      6\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, \u001b[39m#if hvd.rank() == 0 else 0,\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[0;32m      8\u001b[0m )\n","File \u001b[1;32mc:\\Users\\haris\\miniconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filez9qjqgq6.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n","\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\haris\\miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\haris\\miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\haris\\miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\haris\\miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\haris\\miniconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"dropout_2\" \"                 f\"(type Dropout).\n    \n    `rate` must be a scalar tensor or a float in the range [0, 1). Received: rate=1.0\n    \n    Call arguments received by layer \"dropout_2\" \"                 f\"(type Dropout):\n      • inputs=tf.Tensor(shape=(None, 512), dtype=float32)\n      • training=True\n"]}],"source":["history = model.fit(\n","    train_generator,\n","    epochs=epochs,\n","    batch_size=batch_size,\n","    validation_data=validation_generator,\n","    verbose=2, #if hvd.rank() == 0 else 0,\n","    callbacks=callbacks\n",")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM81C9w1diQNinA7BHTJGWi","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
